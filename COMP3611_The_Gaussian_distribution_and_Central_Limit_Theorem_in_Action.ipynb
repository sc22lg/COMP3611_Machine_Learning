{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sc22lg/COMP3611_Machine_Learning/blob/main/COMP3611_The_Gaussian_distribution_and_Central_Limit_Theorem_in_Action.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZLSOAPTVjMdD"
      },
      "source": [
        "<a rel=\"license\" href=\"http://creativecommons.org/licenses/by/4.0/\"><img alt=\"Creative Commons Licence\" style=\"border-width:0\" src=\"https://i.creativecommons.org/l/by/4.0/88x31.png\" /></a><br /><span xmlns:dct=\"http://purl.org/dc/terms/\" property=\"dct:title\">COMP5611M - The Gaussian Distribution and the Central Limit Theorem in Action</span> by <span xmlns:cc=\"http://creativecommons.org/ns#\" property=\"cc:attributionName\">Marc de Kamps and University of Leeds</span> is licensed under a <a rel=\"license\" href=\"http://creativecommons.org/licenses/by/4.0/\">Creative Commons Attribution 4.0 International License</a>."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xtLSDbfFutJo"
      },
      "source": [
        "## Introduction\n",
        "\n",
        "In the previous notebook on simulating stochastic processes, you will have worked through examples of converting a uniform random variable to samples drawn from discrete distributions (e.g. Bernoulli). You will also have seen how uniform random variables can be transformed to a sample from a continuous function/distribution. You will also have seen the form of the univariate Gaussian distribution in the lectures, slides and reader. The univariate Gaussian distribution is defined by two values, its mean $\\mu$ and the standard deviation $\\sigma$. The variance of the distribution is $\\sigma^2$. The probability density function of the univariate Gaussian distribution, for a continuous random variable $x$ is given by,\n",
        "\n",
        "# $\\mathcal{N}(x | \\mu, \\sigma^2) = p(x | \\mu, \\sigma^2) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}} \\exp^{( -\\frac{(x-\\mu)^2)}{2\\sigma^2})}$\n",
        "\n",
        "**Exercise one:** Using these definitions,sample 1000 random variables sampled within the interval ([-10,10]) to samples drawn from univariate Gaussian distribution with mean $\\mu$ = 3.0 and variance $\\sigma^2$ = 2.0. Show a histogram of the data sample. Plot the resulting probability density function (pdf) as a curve, and investigate how you can match the histogram with the density function curve. The *scipy.stats* module contains useful methods for doing this. Consult this page: https://docs.scipy.org/doc/scipy/reference/stats.html and investigate how the *pdf* function can be used to draw probability distributions. Consider using the *pdf* function for. this exercise."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QHcMI5MmuyqW"
      },
      "source": [
        "**Exercise two:** Repeat the above process to plot the pdfs for different univariate Gaussian distributions defined by: $\\mathcal{N}(x | 2.0, 5.0), \\mathcal{N}(x | -1.5, 3.0)$ \\& $\\mathcal{N}(x | -4.0, 0.5)$. Overlay the resulting pdf curves in the same plot."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tX2dVbpWjMdF"
      },
      "source": [
        "**Exercise three**: Eyeball the  curve with $\\mu = 2, \\sigma = 5$. Estimate how much probability of the distribution is contained in the interval $[0,4]$, just by guessing. Then investigate *cumulative density functions* and the way you can access them in *scipy.stats*. Now calculate the amount of probability contained in this interval using *norm.cdf* and state whether this matches your original estimate."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ddeCJFKyu-rV"
      },
      "source": [
        "## The Central Limit Theorem in Action\n",
        "### Objectives\n",
        "\n",
        "In the main text, the cental limit theorem is mentioned. This theorem, somewhat loosely stated, implies that\n",
        "a sum comprised of $N$ terms of stochastic variables, will be distributed approximately according to a normal distribution, even if distribution if the stochastic variables themselves are sampled from a distribution that is not a Guassian. It is assumed that all variables are governed by the same distribution and are independent. The mean and variance of the Gaussian can be estimated in terms of the mean and variance of the non-Gaussian distribution and $N$.\n",
        "\n",
        "In practice, we often sample an unknown distribution $N$ times and calculate its mean. According to the central limit theorem this mean itself follows a distribution that is approximately Gaussian. In this activity, we will simulate  the mean of samples of various distributions and will demonstrate that this indeed follows a\n",
        "Gaussian distribution.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7diiMqHDvF85"
      },
      "source": [
        "**Exercise four:** Generate a sample of 10000 points from a Bernoulli process with $\\mu = 0.6$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mw522wzOvhA9"
      },
      "source": [
        "**Exercise five:** Randomly select 5 individuals from this sample and calculate their sum. Store the result.\n",
        "Repeat this 1000 times. Make a histogram of these 1000 sum values. Write your code flexibly, so that you can\n",
        "experiment with the parameters."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VIFe0oNcvs11"
      },
      "source": [
        "**Exercise six**: The central limit theorem also predicts that if one  estimates $\\mu$ by the sample mean $np$\n",
        "and $\\sigma^2$ by the sample variance $np(1-p)$, the resulting Gaussian distribution function should approximate the histogram of binomial samples. Calculate these quantites for the example above. Then plot a Gaussian distribution function with these parameters in the same figure as the histogram to verify that the histogram is approaching a Gaussian distribution."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JFmTSn0Mwrp5"
      },
      "source": [
        "**Exercise seven**:  Now repeat the entire process with not five, but twenty individuals and then 50 individuals. Explain what you observe and whether the agreement is better or worse than for five individuals."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}